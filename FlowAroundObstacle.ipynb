{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Unsteady Navier-Stokes equations\n",
    "\n",
    "\\begin{cases}\n",
    "       \\dfrac{\\partial \\mathbf{v}(\\mathbf{x},t)}{\\partial t} -\\nu \\Delta \\mathbf{v}(\\mathbf{x},t) + (\\mathbf{v}(\\mathbf{x},t) \\cdot \\nabla) \\mathbf{v}(\\mathbf{x},t) + \\nabla p(\\mathbf{x},t) = 0  \\qquad &\\mathrm{in} \\ \\Omega(\\boldsymbol{\\mu}) \\times (0,T] \\\\\n",
    "       \\mathrm{div }\\  \\mathbf{v}(\\mathbf{x},t) = 0  \\qquad &\\mathrm{in} \\ \\Omega(\\boldsymbol{\\mu}) \\times (0,T) \\\\\n",
    "       \\mathbf{v}(\\mathbf{x},t) = \\mathbf{v}_{\\text{in}}(\\mathbf{x},t;\\boldsymbol{\\mu})  \\qquad &\\mathrm{on} \\ \\Gamma_{\\textrm{in}} \\times (0,T)\\\\\n",
    "       \\mathbf{v}(\\mathbf{x},t) = \\boldsymbol{0} \\qquad &\\mathrm{on} \\ \\Gamma_{\\textrm{obs}} \\times (0,T)\\\\\n",
    "       \\mathbf{v}(\\mathbf{x},t) \\cdot \\mathbf{n}(\\mathbf{x}) = 0  \\qquad &\\mathrm{on} \\ \\Gamma_{\\textrm{walls}} \\times (0,T) \\\\\n",
    "       (\\mu \\nabla \\mathbf{v}(\\mathbf{x},t) - p(\\mathbf{x},t)I)\\mathbf{n}(\\mathbf{x}) \\cdot \\mathbf{t}(\\mathbf{x}) = 0  \\qquad &\\mathrm{on} \\ \\Gamma_{\\textrm{walls}} \\times (0,T) \\\\\n",
    "       (\\mu \\nabla \\mathbf{v}(\\mathbf{x},t) - p(\\mathbf{x},t)I)\\mathbf{n}(\\mathbf{x}) = 0  \\qquad &\\mathrm{on} \\ \\Gamma_{\\textrm{out}} \\times (0,T)\\\\\n",
    "       \\mathbf{v}(\\mathbf{x},0) = \\boldsymbol{0} &\\mathrm{in} \\ \\Omega(\\boldsymbol{\\mu}) \\times \\{t = 0\\}\n",
    "\\end{cases}\n",
    "\n",
    "where $\\Omega(\\boldsymbol{\\mu})$ is the domain of interest depending on the parameters $\\boldsymbol{\\mu}$ in the parameter space $\\mathcal{P}$, $T > 0$ is the final time, $\\mathbf{v}(\\mathbf{x},t): \\Omega \\times [0,T] \\to \\mathbb{R}^2$ is the unknown velocity, $p(\\mathbf{x},t): \\Omega \\times [0,T] \\to \\mathbb{R}$ is the unknown pressure, $\\mathbf{v}_{\\text{in}}(\\mathbf{x},t;\\boldsymbol{\\mu}): \\Gamma_{\\textrm{in}} \\times [0,T] \\to \\mathbb{R}^2$ is the time and parameters-dependent inflow datum, $\\nu$ is the kinematic viscosity, $\\mathbf{n}(\\mathbf{x})$ and $\\mathbf{t}(\\mathbf{x})$ are the normal and tangential versors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "jV7rgAvVG4ue"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "A module that was compiled using NumPy 1.x cannot be run in\n",
      "NumPy 2.2.6 as it may crash. To support both 1.x and 2.x\n",
      "versions of NumPy, modules must be compiled with NumPy 2.0.\n",
      "Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.\n",
      "\n",
      "If you are a user of the module, the easiest solution will be to\n",
      "downgrade to 'numpy<2' or try to upgrade the affected module.\n",
      "We expect that some modules will need time to support NumPy 2.\n",
      "\n",
      "Traceback (most recent call last):  File \"/Users/markussandnes/anaconda3/envs/fenics_torch/lib/python3.10/runpy.py\", line 196, in _run_module_as_main\n",
      "    return _run_code(code, main_globals, None,\n",
      "  File \"/Users/markussandnes/anaconda3/envs/fenics_torch/lib/python3.10/runpy.py\", line 86, in _run_code\n",
      "    exec(code, run_globals)\n",
      "  File \"/Users/markussandnes/anaconda3/envs/fenics_torch/lib/python3.10/site-packages/ipykernel_launcher.py\", line 18, in <module>\n",
      "    app.launch_new_instance()\n",
      "  File \"/Users/markussandnes/anaconda3/envs/fenics_torch/lib/python3.10/site-packages/traitlets/config/application.py\", line 1075, in launch_instance\n",
      "    app.start()\n",
      "  File \"/Users/markussandnes/anaconda3/envs/fenics_torch/lib/python3.10/site-packages/ipykernel/kernelapp.py\", line 739, in start\n",
      "    self.io_loop.start()\n",
      "  File \"/Users/markussandnes/anaconda3/envs/fenics_torch/lib/python3.10/site-packages/tornado/platform/asyncio.py\", line 211, in start\n",
      "    self.asyncio_loop.run_forever()\n",
      "  File \"/Users/markussandnes/anaconda3/envs/fenics_torch/lib/python3.10/asyncio/base_events.py\", line 603, in run_forever\n",
      "    self._run_once()\n",
      "  File \"/Users/markussandnes/anaconda3/envs/fenics_torch/lib/python3.10/asyncio/base_events.py\", line 1909, in _run_once\n",
      "    handle._run()\n",
      "  File \"/Users/markussandnes/anaconda3/envs/fenics_torch/lib/python3.10/asyncio/events.py\", line 80, in _run\n",
      "    self._context.run(self._callback, *self._args)\n",
      "  File \"/Users/markussandnes/anaconda3/envs/fenics_torch/lib/python3.10/site-packages/ipykernel/kernelbase.py\", line 519, in dispatch_queue\n",
      "    await self.process_one()\n",
      "  File \"/Users/markussandnes/anaconda3/envs/fenics_torch/lib/python3.10/site-packages/ipykernel/kernelbase.py\", line 508, in process_one\n",
      "    await dispatch(*args)\n",
      "  File \"/Users/markussandnes/anaconda3/envs/fenics_torch/lib/python3.10/site-packages/ipykernel/kernelbase.py\", line 400, in dispatch_shell\n",
      "    await result\n",
      "  File \"/Users/markussandnes/anaconda3/envs/fenics_torch/lib/python3.10/site-packages/ipykernel/ipkernel.py\", line 368, in execute_request\n",
      "    await super().execute_request(stream, ident, parent)\n",
      "  File \"/Users/markussandnes/anaconda3/envs/fenics_torch/lib/python3.10/site-packages/ipykernel/kernelbase.py\", line 767, in execute_request\n",
      "    reply_content = await reply_content\n",
      "  File \"/Users/markussandnes/anaconda3/envs/fenics_torch/lib/python3.10/site-packages/ipykernel/ipkernel.py\", line 455, in do_execute\n",
      "    res = shell.run_cell(\n",
      "  File \"/Users/markussandnes/anaconda3/envs/fenics_torch/lib/python3.10/site-packages/ipykernel/zmqshell.py\", line 577, in run_cell\n",
      "    return super().run_cell(*args, **kwargs)\n",
      "  File \"/Users/markussandnes/anaconda3/envs/fenics_torch/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 3077, in run_cell\n",
      "    result = self._run_cell(\n",
      "  File \"/Users/markussandnes/anaconda3/envs/fenics_torch/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 3132, in _run_cell\n",
      "    result = runner(coro)\n",
      "  File \"/Users/markussandnes/anaconda3/envs/fenics_torch/lib/python3.10/site-packages/IPython/core/async_helpers.py\", line 128, in _pseudo_sync_runner\n",
      "    coro.send(None)\n",
      "  File \"/Users/markussandnes/anaconda3/envs/fenics_torch/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 3336, in run_cell_async\n",
      "    has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n",
      "  File \"/Users/markussandnes/anaconda3/envs/fenics_torch/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 3519, in run_ast_nodes\n",
      "    if await self.run_code(code, result, async_=asy):\n",
      "  File \"/Users/markussandnes/anaconda3/envs/fenics_torch/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 3579, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"/var/folders/21/q6thhsn14n7gnn88h4prdf1h0000gn/T/ipykernel_33774/3799178578.py\", line 4, in <module>\n",
      "    import torch\n",
      "  File \"/Users/markussandnes/anaconda3/envs/fenics_torch/lib/python3.10/site-packages/torch/__init__.py\", line 1477, in <module>\n",
      "    from .functional import *  # noqa: F403\n",
      "  File \"/Users/markussandnes/anaconda3/envs/fenics_torch/lib/python3.10/site-packages/torch/functional.py\", line 9, in <module>\n",
      "    import torch.nn.functional as F\n",
      "  File \"/Users/markussandnes/anaconda3/envs/fenics_torch/lib/python3.10/site-packages/torch/nn/__init__.py\", line 1, in <module>\n",
      "    from .modules import *  # noqa: F403\n",
      "  File \"/Users/markussandnes/anaconda3/envs/fenics_torch/lib/python3.10/site-packages/torch/nn/modules/__init__.py\", line 35, in <module>\n",
      "    from .transformer import TransformerEncoder, TransformerDecoder, \\\n",
      "  File \"/Users/markussandnes/anaconda3/envs/fenics_torch/lib/python3.10/site-packages/torch/nn/modules/transformer.py\", line 20, in <module>\n",
      "    device: torch.device = torch.device(torch._C._get_default_device()),  # torch.device('cpu'),\n",
      "/Users/markussandnes/anaconda3/envs/fenics_torch/lib/python3.10/site-packages/torch/nn/modules/transformer.py:20: UserWarning: Failed to initialize NumPy: _ARRAY_API not found (Triggered internally at /Users/runner/work/pytorch/pytorch/pytorch/torch/csrc/utils/tensor_numpy.cpp:84.)\n",
      "  device: torch.device = torch.device(torch._C._get_default_device()),  # torch.device('cpu'),\n"
     ]
    },
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'seaborn'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 7\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mnumpy\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpyplot\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mplt\u001b[39;00m\n\u001b[0;32m----> 7\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mseaborn\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01msns\u001b[39;00m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01msys\u001b[39;00m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m__future__\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m print_function\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'seaborn'"
     ]
    }
   ],
   "source": [
    "#IMPORT LIBRARIES\n",
    "\n",
    "from dolfin import *\n",
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import sys\n",
    "from __future__ import print_function\n",
    "from IPython.display import clear_output as clc\n",
    "\n",
    "plt.style.use(\"default\")\n",
    "set_log_level(LogLevel.ERROR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DEFINE COLORMAP\n",
    "\n",
    "from matplotlib import colors\n",
    "ice = sns.color_palette(\"icefire\", as_cmap=True).colors\n",
    "col = [ice[i] for i in np.concatenate((np.arange(128,0,-10), np.arange(254,128,-9)))]\n",
    "col.insert(0, \"black\")\n",
    "cmap = colors.LinearSegmentedColormap.from_list(\"\", col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MESH MORPHING\n",
    "\n",
    "from scipy.interpolate import RBFInterpolator\n",
    "\n",
    "def mesh_generator(obstacle_horizontal_semiaxis_left, obstacle_horizontal_semiaxis_right):\n",
    "    \"\"\"\n",
    "    Mesh generation through RBF interpolation\n",
    "    Input: geometric parameters representing the left semi-major and right semi-major axis of the obstacle\n",
    "    Output: mesh with the proper obstacle\n",
    "    \"\"\"\n",
    "    x_center = y_center = 1.0\n",
    "    radius = 0.2\n",
    "    mesh = Mesh(\"FlowAroundObstacle_mesh_reference.xml\")\n",
    "\n",
    "    control_points = np.array([[x_center - radius, y_center], [x_center, y_center - radius], [x_center + radius, y_center], [x_center, y_center + radius]])\n",
    "    displacements = np.array([[radius - obstacle_horizontal_semiaxis_left, 0.0], [0.0, 0.0], [obstacle_horizontal_semiaxis_right - radius, 0.0], [0.0, 0.0]])\n",
    "\n",
    "    x0 = y0 = 0.0\n",
    "    x1 = 10.0\n",
    "    y1 = 2.0\n",
    "    step_size = 0.1  \n",
    "    wall1_points = np.column_stack((np.arange(x0, x1, step_size), np.zeros(round(x1/step_size))))\n",
    "    wall2_points = np.column_stack((x1 * np.ones(round(y1/step_size)), np.arange(y0, y1, step_size)))\n",
    "    wall3_points = np.column_stack((np.arange(x1, x0, -step_size), y1 * np.ones(round(x1/step_size))))\n",
    "    wall4_points = np.column_stack((np.zeros(round(y1/step_size)), np.arange(y1, y0, -step_size)))\n",
    "    \n",
    "    control_points = np.row_stack((control_points, wall1_points, wall2_points, wall3_points, wall4_points))\n",
    "    displacements = np.row_stack((displacements, np.zeros((wall1_points.shape[0] + wall2_points.shape[0] + wall3_points.shape[0] + wall4_points.shape[0], 2))))\n",
    "    \n",
    "    rbf = RBFInterpolator(control_points, displacements)\n",
    "    displacements = rbf(mesh.coordinates())\n",
    "\n",
    "    Dh = VectorFunctionSpace(mesh, \"CG\", 1)\n",
    "    d = Function(Dh)\n",
    "    v2d = vertex_to_dof_map(Dh).reshape((-1, mesh.geometry().dim()))\n",
    "    for i in range(v2d.shape[0]):\n",
    "        d.vector()[v2d[i]] = displacements[i]\n",
    "    \n",
    "    ALE.move(mesh, d)\n",
    "    \n",
    "    return mesh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MESH EXAMPLE (PLOT)\n",
    "\n",
    "plt.figure(figsize = (10, 5))\n",
    "mesh = mesh_generator(0.6, 1.0)\n",
    "plot(mesh, color = \"grey\", linewidth = 0.5)\n",
    "plt.title(\"Mesh ($N_{h}$=%d)\" % mesh.num_vertices())\n",
    "plt.axis('off');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DEFINE THE UNSTEADY NAVIER-STOKES SOLVER\n",
    "\n",
    "from tqdm import tqdm\n",
    "    \n",
    "def boundary_conditions(params_ph, Vh, Ph):\n",
    "    '''\n",
    "    Define boundary conditions (once for all)\n",
    "    Input: physical parameters, velocity and pressure functional spaces\n",
    "    Output: boundary conditions for velocity and pressure\n",
    "    '''\n",
    "\n",
    "    alpha_in = params_ph[0]\n",
    "    mod_in = params_ph[1]\n",
    "    \n",
    "    # Parabolic BC on the inflow\n",
    "    v_in = Expression(('mod_in * cos(alpha_in)','x[1] * (2.0 - x[1]) * mod_in * sin(alpha_in)'), degree = 2, mod_in = mod_in, alpha_in = alpha_in)  \n",
    "    inflow = DirichletBC(Vh, v_in, \"on_boundary && x[0] < 0.001\")\n",
    "    \n",
    "    # Free-slip BC on the wall\n",
    "    wall = DirichletBC(Vh.sub(1), 0.0, \"on_boundary && (x[1] > 1.999 || x[1] < 0.001)\")\n",
    "    \n",
    "    # No-slip BC on the obstacle\n",
    "    obstacle = DirichletBC(Vh, (0.0, 0.0), \"on_boundary && (x[0] - 1.0) * (x[0] - 1.0) + (x[1] - 1.0) *  (x[1] - 1.0) < 0.7 * 0.7\")\n",
    "\n",
    "    # BC for the velocity\n",
    "    bcv = [inflow, wall, obstacle]\n",
    "    \n",
    "    # BC for the pressure required by Chorin-Temam method\n",
    "    bcp = DirichletBC(Ph, 0.0, \"on_boundary && x[0] > 9.999\")\n",
    "    \n",
    "    return [bcv, bcp]\n",
    "\n",
    "def chorin_assembly(Vh, Ph, dx):\n",
    "    '''\n",
    "    Assembly for the time-independent matrices of the Chorin steps\n",
    "    Input: velocity and pressure functional spaces, space measure\n",
    "    Outputs: assembled matrices\n",
    "    '''\n",
    "    \n",
    "    w = TestFunction(Vh)\n",
    "    q = TestFunction(Ph)\n",
    "    v = TrialFunction(Vh)\n",
    "    p = TrialFunction(Ph)\n",
    "\n",
    "    # Second step\n",
    "    a2 = inner(grad(p), grad(q)) * dx\n",
    "    A2 = assemble(a2)\n",
    "    \n",
    "    # Third step\n",
    "    a3 = inner(v, w) * dx\n",
    "    A3 = assemble(a3)\n",
    "    \n",
    "    # Fourth step\n",
    "    a4 = p * q * dx\n",
    "    A4 = assemble(a4)\n",
    "    \n",
    "    return [A2, A3, A4] \n",
    "    \n",
    "def compute_state(params, dt, ntimesteps):\n",
    "    '''\n",
    "    Compute unsteady velocity and pressure via incremental Chorin-Temam projection method\n",
    "    Input: physical and geometric parameters, time step and number of time steps \n",
    "    Output: time-dependent velocity and pressure\n",
    "    '''\n",
    "\n",
    "    # Define parameters\n",
    "    nu = 0.01                                          # Flow viscosity\n",
    "    alpha_in = params[0][0]                            # Angle of attack\n",
    "    mod_in = params[1][0]                              # Inflow intensity\n",
    "    obstacle_horizontal_semiaxis_left = params[2][0]   # Obstacle horizontal left-semiaxis length\n",
    "    obstacle_horizontal_semiaxis_right = params[3][0]  # Obstacle horizontal right-semiaxis length\n",
    "\n",
    "    # Create mesh\n",
    "    mesh = mesh_generator(obstacle_horizontal_semiaxis_left, obstacle_horizontal_semiaxis_right)\n",
    "    \n",
    "    # Define measures\n",
    "    dx = Measure(\"dx\", domain = mesh)\n",
    "    ds = Measure(\"ds\", domain = mesh)\n",
    "\n",
    "    # Define functional spaces\n",
    "    Vh = VectorFunctionSpace(mesh, \"CG\", 2)\n",
    "    Ph = FunctionSpace(mesh, \"CG\", 1)\n",
    "\n",
    "    # Define test functions    \n",
    "    w = TestFunction(Vh)\n",
    "    q = TestFunction(Ph)\n",
    "    v = TrialFunction(Vh)\n",
    "    p = TrialFunction(Ph)\n",
    "    v1 = Function(Vh)\n",
    "    p1 = Function(Ph)\n",
    "\n",
    "    # Define initial conditions\n",
    "    v0 = Function(Vh)\n",
    "    p0 = Function(Ph)\n",
    "    \n",
    "    # Chorin assembly for time-independent matrices\n",
    "    [A2, A3, A4] = chorin_assembly(Vh, Ph, dx)\n",
    "    \n",
    "    vt = torch.zeros(ntimesteps, Vh.dim())\n",
    "    pt = torch.zeros(ntimesteps, Ph.dim())\n",
    "    \n",
    "    t = float(dt)\n",
    "    \n",
    "    for i in tqdm(range(ntimesteps), colour = \"cyan\", file = sys.stdout, bar_format = 'Snapshots generation |{bar}| {n}/{total} {elapsed}<{remaining}'):\n",
    "        \n",
    "        # Compute boundary conditions\n",
    "        [bcv, bcp] = boundary_conditions([params[0][i], params[1][i]], Vh, Ph)\n",
    "\n",
    "        # First Chorin-Temam step\n",
    "        a1 = (1 / dt) * inner(v, w) * dx + inner(grad(v) * v0, w) * dx + nu * inner(grad(v), grad(w)) * dx \n",
    "        A1 = assemble(a1)\n",
    "        L1 = (1 / dt) * inner(v0, w) * dx - inner(grad(p0), w) * dx\n",
    "        b1 = assemble(L1)\n",
    "        [bc.apply(A1, b1) for bc in bcv]\n",
    "        solve(A1, v1.vector(), b1)\n",
    "        \n",
    "        # Second Chorin-Temam step\n",
    "        L2 = - (1 / dt) * div(v1) * q * dx\n",
    "        b2 = assemble(L2)\n",
    "        bcp.apply(A2, b2)\n",
    "        solve(A2, p1.vector(), b2)\n",
    "        \n",
    "        # Third Chorin-Temam step\n",
    "        L3 = inner(v1, w) * dx - dt * inner(grad(p1), w) * dx\n",
    "        b3 = assemble(L3)\n",
    "        solve(A3, v1.vector(), b3)\n",
    "        \n",
    "        # Fourth Chorin-Temam step\n",
    "        L4 = p0 * q * dx + p1 * q * dx\n",
    "        b4 = assemble(L4)\n",
    "        solve(A4, p1.vector(), b4)\n",
    "   \n",
    "        v0.assign(v1)\n",
    "        p0.assign(p1)\n",
    "        vt[i] = torch.tensor(v1.vector())\n",
    "        pt[i] = torch.tensor(p1.vector())\n",
    "        t = t + float(dt)\n",
    "    \n",
    "    return [vt, pt]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Snapshots generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GENERATE SNAPSHOTS WITH CONSTANT PARAMETERS (SKIP THIS CELL IF DATA ALREADY AVAILABLE)\n",
    "\n",
    "dt = Constant(0.05)\n",
    "T = 10.0\n",
    "ntimesteps = round(T / dt)\n",
    "ntimes = ntimesteps # Time series length\n",
    "\n",
    "ntrajectories = 100\n",
    "nparams = 4\n",
    "nvelocity = VectorFunctionSpace(Mesh(\"FlowAroundObstacle_mesh_reference.xml\"), \"CG\", 2).dim()\n",
    "npressure = FunctionSpace(Mesh(\"FlowAroundObstacle_mesh_reference.xml\"), \"CG\", 1).dim()\n",
    "\n",
    "params_ph_range = [(-1.0, 1.0), (1.0, 10.0)] # Physical parameters: angle of attack and inflow intensity\n",
    "params_geo_range = [(0.2, 0.6), (0.2, 1.0)]  # Geometric parameters: obstacle horizontal semiaxes dimensions (left and right)\n",
    "params_range = params_ph_range + params_geo_range\n",
    "\n",
    "filename = 'FlowAroundObstacle_data'\n",
    "V = torch.zeros(ntrajectories, ntimes, nvelocity)\n",
    "P = torch.zeros(ntrajectories, ntimes, npressure)\n",
    "MU = torch.zeros(ntrajectories, ntimes, nparams)\n",
    "\n",
    "for i in range(ntrajectories):\n",
    " \n",
    "    print(f\"Generating snapshots n.{i}...\")\n",
    "\n",
    "    params = [0] * len(params_range)\n",
    "    for j in range(len(params_range)):\n",
    "        params[j] = ((params_range[j][1] - params_range[j][0]) * torch.rand(1) + params_range[j][0]).item()  \n",
    "    \n",
    "    alpha_in = []\n",
    "    mod_in = []\n",
    "    obstacle_horizontal_semiaxis_left = []\n",
    "    obstacle_horizontal_semiaxis_right = []\n",
    "    for j in range(ntimesteps):\n",
    "        alpha_in.append(params[1])\n",
    "        mod_in.append(params[2])\n",
    "        obstacle_horizontal_semiaxis_left.append(params[3])\n",
    "        obstacle_horizontal_semiaxis_right.append(params[4])\n",
    "\n",
    "    params_ph = [alpha_in, mod_in]                                                       # Physical parameters: angle of attack and inflow intensity\n",
    "    params_geo = [obstacle_horizontal_semiaxis_left, obstacle_horizontal_semiaxis_right] # Geometric parameters: obstacle horizontal semiaxes dimensions (left and right)\n",
    "\n",
    "    [vt, pt] = compute_state(params_ph + params_geo, dt, ntimesteps)\n",
    "\n",
    "    V[i] = vt\n",
    "    P[i] = pt\n",
    "    MU[i, :, 0] = torch.tensor(alpha_in)\n",
    "    MU[i, :, 1] = torch.tensor(mod_in)\n",
    "    MU[i, :, 2] = torch.tensor(obstacle_horizontal_semiaxis_left)\n",
    "    MU[i, :, 3] = torch.tensor(obstacle_horizontal_semiaxis_right)\n",
    "\n",
    "    clc(wait = True)\n",
    "\n",
    "print(\"Snapshots generated!\")\n",
    "\n",
    "np.savez(\"%s.npz\" % filename.replace(\".npz\",\"\"), v = V, p = P, mu = MU)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GENERATE SNAPSHOTS WITH TIME-DEPENDENT PARAMETERS (SKIP THIS CELL IF DATA ALREADY AVAILABLE)\n",
    "\n",
    "dt = Constant(0.05)\n",
    "T = 10.0\n",
    "ntimesteps = round(T / dt)\n",
    "ntimes = ntimesteps # Time series length\n",
    "\n",
    "ntrajectories = 100\n",
    "nparams = 4\n",
    "nvelocity = VectorFunctionSpace(Mesh(\"FlowAroundObstacle_mesh_reference.xml\"), \"CG\", 2).dim()\n",
    "npressure = FunctionSpace(Mesh(\"FlowAroundObstacle_mesh_reference.xml\"), \"CG\", 1).dim()\n",
    "\n",
    "params_ph_range = [(2.5, 20), (0, 2*pi), (1.0, 10.0)] # Physical parameters ranges: period and phase of time-dependent angle of attack and inflow intensity\n",
    "params_geo_range = [(0.2, 0.6), (0.2, 1.0)]           # Geometric parameters ranges: obstacle horizontal semiaxes dimensions (left and right)\n",
    "params_range = params_ph_range + params_geo_range\n",
    "\n",
    "filename = 'FlowAroundObstacle_UnsteadyParam_data'\n",
    "V = torch.zeros(ntrajectories, ntimes, nvelocity)\n",
    "P = torch.zeros(ntrajectories, ntimes, npressure)\n",
    "MU = torch.zeros(ntrajectories, ntimes, nparams)\n",
    "\n",
    "for i in range(ntrajectories):\n",
    " \n",
    "    print(f\"Generating snapshots n.{i}...\")\n",
    "\n",
    "    params = [0] * len(params_range)\n",
    "    for j in range(len(params_range)):\n",
    "        params[j] = ((params_range[j][1] - params_range[j][0]) * torch.rand(1) + params_range[j][0]).item()  \n",
    "    \n",
    "    alpha_in = []\n",
    "    mod_in = []\n",
    "    obstacle_horizontal_semiaxis_left = []\n",
    "    obstacle_horizontal_semiaxis_right = []\n",
    "    for j in range(ntimesteps):\n",
    "        alpha_in.append(cos(2*pi*float(dt)*j/params[0] + params[1]))\n",
    "        mod_in.append(params[2])\n",
    "        obstacle_horizontal_semiaxis_left.append(params[3])\n",
    "        obstacle_horizontal_semiaxis_right.append(params[4])\n",
    "\n",
    "    params_ph = [alpha_in, mod_in]                                                       # Physical parameters: angle of attack and inflow intensity\n",
    "    params_geo = [obstacle_horizontal_semiaxis_left, obstacle_horizontal_semiaxis_right] # Geometric parameters: obstacle horizontal semiaxes dimensions (left and right)\n",
    "\n",
    "    [vt, pt] = compute_state(params_ph + params_geo, dt, ntimesteps)\n",
    "\n",
    "    V[i] = vt\n",
    "    P[i] = pt\n",
    "    MU[i, :, 0] = torch.tensor(alpha_in)\n",
    "    MU[i, :, 1] = torch.tensor(mod_in)\n",
    "    MU[i, :, 2] = torch.tensor(obstacle_horizontal_semiaxis_left)\n",
    "    MU[i, :, 3] = torch.tensor(obstacle_horizontal_semiaxis_right)\n",
    "\n",
    "    clc(wait = True)\n",
    "\n",
    "print(\"Snapshots generated!\")\n",
    "\n",
    "np.savez(\"%s.npz\" % filename.replace(\".npz\",\"\"), v = V, p = P, mu = MU)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LOAD SNAPSHOTS MATRICES\n",
    "\n",
    "dt = Constant(0.05)\n",
    "T = 10.0\n",
    "ntimesteps = round(T / dt)\n",
    "ntimes = ntimesteps # Time series length\n",
    "\n",
    "ntrajectories = 200\n",
    "nparams = 4\n",
    "nvelocity = VectorFunctionSpace(Mesh(\"FlowAroundObstacle_mesh_reference.xml\"), \"CG\", 2).dim()\n",
    "npressure = FunctionSpace(Mesh(\"FlowAroundObstacle_mesh_reference.xml\"), \"CG\", 1).dim()\n",
    "\n",
    "filename1 = 'FlowAroundObstacle_data'\n",
    "Data1 = np.load(\"%s.npz\" % filename1.replace(\".npz\",\"\"))\n",
    "\n",
    "filename2 = 'FlowAroundObstacle_UnsteadyParam_data'\n",
    "Data2 = np.load(\"%s.npz\" % filename2.replace(\".npz\",\"\"))\n",
    "\n",
    "V = torch.cat((torch.tensor(Data1[\"v\"]), torch.tensor(Data2[\"v\"])), 0)\n",
    "P = torch.cat((torch.tensor(Data1[\"p\"]), torch.tensor(Data2[\"p\"])), 0)\n",
    "MU = torch.cat((torch.tensor(Data1[\"mu\"]), torch.tensor(Data2[\"mu\"])), 0)\n",
    "\n",
    "del Data1, Data2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FUNCTIONS TO CONVERT VECTORS INTO FUNCTIONS\n",
    "\n",
    "def vec2vel(vec, params_geo):\n",
    "    '''\n",
    "    Convert a vector into a fenics velocity function\n",
    "    Input: vector of degrees of freedom and geometric parameters\n",
    "    Output: function\n",
    "    '''\n",
    "    mesh = mesh_generator(params_geo[0], params_geo[1])\n",
    "    Vh = VectorFunctionSpace(mesh, \"CG\", 2)\n",
    "    v = Function(Vh)\n",
    "    v.vector()[:] = vec\n",
    "    return v\n",
    "    \n",
    "def vec2pre(vec, params):\n",
    "    '''\n",
    "    Convert a vector into a fenics pressure function\n",
    "    Input: vector of degrees of freedom and geometric parameters\n",
    "    Output: function\n",
    "    '''\n",
    "    mesh = mesh_generator(params_geo[0], params_geo[1])\n",
    "    Ph = FunctionSpace(mesh, \"CG\", 1)\n",
    "    p = Function(Ph)\n",
    "    p.vector()[:] = vec\n",
    "    return p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# VELOCITY TRAJECTORY EXAMPLE (PLOT)\n",
    "\n",
    "from utils.processdata import trajectory\n",
    "\n",
    "whichtrajectory = 0\n",
    "whichtimes = np.arange(0, 20)\n",
    "\n",
    "params_geo = MU[whichtrajectory, 0, 2:]\n",
    "vmin = V[whichtrajectory, whichtimes].abs().min()\n",
    "vmax = V[whichtrajectory, whichtimes].abs().max()\n",
    "\n",
    "def plot_velocity(v):\n",
    "    v = vec2vel(v, params_geo)\n",
    "    plot(sqrt(inner(v, v)), cmap = cmap, vmin = vmin, vmax = vmax)\n",
    "\n",
    "trajectory(V[whichtrajectory, whichtimes], plot_velocity, title = \"Velocity trajectory\", figsize = (10, 10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PRESSURE TRAJECTORY EXAMPLE (PLOT)\n",
    "\n",
    "whichtrajectory = 0\n",
    "whichtimes = np.arange(0, 20)\n",
    "\n",
    "params_geo = MU[whichtrajectory, 0, 2:]\n",
    "\n",
    "def plot_pressure(p):\n",
    "    p = vec2pre(p, params_geo)\n",
    "    plot(p, cmap = \"jet\")\n",
    "\n",
    "trajectory(P[whichtrajectory, whichtimes], plot_pressure, title = \"Pressure trajectory\", figsize = (10, 10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SPLIT VELOCITY MATRIX IN THE X AND Y COMPONENTS\n",
    "\n",
    "Vx = V[:, :, 0 : nvelocity : 2]\n",
    "Vy = V[:, :, 1 : nvelocity : 2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TRAIN-VALIDATION-TEST SPLITTING\n",
    "\n",
    "np.random.seed(0)\n",
    "\n",
    "ntrain = round(0.8 * ntrajectories)\n",
    "\n",
    "idx_train = np.random.choice(ntrajectories, size = ntrain, replace = False)\n",
    "mask = np.ones(ntrajectories)\n",
    "mask[idx_train] = 0\n",
    "idx_valid_test = np.arange(0, ntrajectories)[np.where(mask!=0)[0]]\n",
    "idx_valid = idx_valid_test[::2]\n",
    "idx_test = idx_valid_test[1::2]\n",
    "\n",
    "nvalid = idx_valid.shape[0]\n",
    "ntest = idx_test.shape[0]\n",
    "\n",
    "Vtrain = V[idx_train]\n",
    "Vvalid = V[idx_valid]\n",
    "Vtest = V[idx_test]\n",
    "Vxtrain = Vx[idx_train]\n",
    "Vxvalid = Vx[idx_valid]\n",
    "Vxtest = Vx[idx_test]\n",
    "Vytrain = Vy[idx_train]\n",
    "Vyvalid = Vy[idx_valid]\n",
    "Vytest = Vy[idx_test]\n",
    "Ptrain = P[idx_train]\n",
    "Pvalid = P[idx_valid]\n",
    "Ptest = P[idx_test]\n",
    "MUtrain = MU[idx_train]\n",
    "MUvalid = MU[idx_valid]\n",
    "MUtest = MU[idx_test]\n",
    "\n",
    "del V, Vx, Vy, P, MU"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Velocity reduction - POD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# IMPORT FUNCTIONS FOR COMPUTING ERRORS\n",
    "\n",
    "from utils.processdata import mae, mre, num2p # Error metrics and format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RESHAPE MATRICES\n",
    "\n",
    "Vxtrain = Vxtrain.reshape(-1, nvelocity//2).numpy()\n",
    "Vxvalid = Vxvalid.reshape(-1, nvelocity//2).numpy()\n",
    "Vxtest = Vxtest.reshape(-1, nvelocity//2).numpy()\n",
    "Vytrain = Vytrain.reshape(-1, nvelocity//2).numpy()\n",
    "Vyvalid = Vyvalid.reshape(-1, nvelocity//2).numpy()\n",
    "Vytest = Vytest.reshape(-1, nvelocity//2).numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PRINCIPAL ORTHOGONAL DECOMPOSITION\n",
    "\n",
    "from sklearn.utils.extmath import randomized_svd\n",
    "\n",
    "kvelocity = 150 # Number of POD modes\n",
    "\n",
    "Ux, Sx, Wx = randomized_svd(Vxtrain, n_components = kvelocity//2)\n",
    "\n",
    "Uy, Sy, Wy = randomized_svd(Vytrain, n_components = kvelocity//2)\n",
    "\n",
    "teal = sns.light_palette(\"teal\", 15)\n",
    "plt.figure(figsize = (15, 5))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot([i for i in range(1, kvelocity//2 + 1)], Sx, color = teal[14], marker = 's', markersize = 5, linewidth = 1)\n",
    "plt.ticklabel_format(axis = 'y', style = 'sci', scilimits = (0,0))\n",
    "plt.loglog(kvelocity//2, Sx[kvelocity//2-1], color = teal[14], marker = 's', linestyle = '--')\n",
    "plt.title(\"Singular values decay - Vx\");\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot([i for i in range(1, kvelocity//2 + 1)], Sy, color = teal[14], marker = 's', markersize = 5, linewidth = 1)\n",
    "plt.ticklabel_format(axis = 'y', style = 'sci', scilimits = (0,0))\n",
    "plt.loglog(kvelocity//2, Sy[kvelocity//2-1], color = teal[14], marker = 's', linestyle = '--')\n",
    "plt.title(\"Singular values decay - Vy\");\n",
    "\n",
    "Vxtrain_POD = Vxtrain @ Wx.transpose()\n",
    "Vxvalid_POD = Vxvalid @ Wx.transpose()\n",
    "Vxtest_POD = Vxtest @ Wx.transpose()\n",
    "Vxtrain_reconstructed = Ux @ np.diag(Sx) @ Wx\n",
    "Vxvalid_reconstructed = Vxvalid @ Wx.transpose() @ Wx\n",
    "Vxtest_reconstructed = Vxtest @ Wx.transpose() @ Wx\n",
    "\n",
    "Vytrain_POD = Vytrain @ Wy.transpose()\n",
    "Vyvalid_POD = Vyvalid @ Wy.transpose()\n",
    "Vytest_POD = Vytest @ Wy.transpose()\n",
    "Vytrain_reconstructed = Uy @ np.diag(Sy) @ Wy\n",
    "Vyvalid_reconstructed = Vyvalid @ Wy.transpose() @ Wy\n",
    "Vytest_reconstructed = Vytest @ Wy.transpose() @ Wy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# POD MODES ON THE REFERENCE MESH (PLOT)\n",
    "\n",
    "from utils.processdata import multiplot\n",
    "\n",
    "plotlist = [Wx[0], Wx[1], Wx[2]]\n",
    "\n",
    "def plot_vx(v):  \n",
    "    mesh = mesh_generator(0.2, 0.2)\n",
    "    Vh = VectorFunctionSpace(mesh, \"CG\", 2)\n",
    "    vfun = Function(Vh.sub(0).collapse())\n",
    "    vfun.vector()[:] = v  \n",
    "    plot(vfun, cmap = cmap)\n",
    "\n",
    "multiplot(plotlist, plot_vx, titles = (\"First POD mode - Vx\", \"Second POD mode - Vx\", \"Third POD mode - Vx\"), figsize = (10, 5), vertical = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# POD MODES ON THE REFERENCE MESH (PLOT)\n",
    "\n",
    "from utils.processdata import multiplot\n",
    "\n",
    "plotlist = [Wy[0], Wy[1], Wy[2]]\n",
    "def plot_vy(v):  \n",
    "    mesh = mesh_generator(0.2, 0.2)\n",
    "    Vh = VectorFunctionSpace(mesh, \"CG\", 2)\n",
    "    vfun = Function(Vh.sub(1).collapse())\n",
    "    vfun.vector()[:] = v  \n",
    "    plot(vfun, cmap = cmap)\n",
    "\n",
    "multiplot(plotlist, plot_vy, titles = (\"First POD mode - Vy\", \"Second POD mode - Vy\", \"Third POD mode - Vy\"), figsize = (10, 5), vertical = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SCALING\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "scalerVx = MinMaxScaler()\n",
    "scalerVx = scalerVx.fit(Vxtrain_POD)\n",
    "Vxtrain_POD = scalerVx.transform(Vxtrain_POD)\n",
    "Vxvalid_POD = scalerVx.transform(Vxvalid_POD)\n",
    "Vxtest_POD = scalerVx.transform(Vxtest_POD)\n",
    "\n",
    "scalerVy = MinMaxScaler()\n",
    "scalerVy = scalerVy.fit(Vytrain_POD)\n",
    "Vytrain_POD = scalerVy.transform(Vytrain_POD)\n",
    "Vyvalid_POD = scalerVy.transform(Vyvalid_POD)\n",
    "Vytest_POD = scalerVy.transform(Vytest_POD)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RESHAPE MATRICES\n",
    "\n",
    "Vxtrain = torch.from_numpy(Vxtrain.reshape(ntrain, ntimes, nvelocity//2))\n",
    "Vxvalid = torch.from_numpy(Vxvalid.reshape(nvalid, ntimes, nvelocity//2))\n",
    "Vxtest = torch.from_numpy(Vxtest.reshape(ntest, ntimes, nvelocity//2))\n",
    "Vxtrain_POD = torch.from_numpy(Vxtrain_POD.reshape(ntrain, ntimes, kvelocity//2))\n",
    "Vxvalid_POD = torch.from_numpy(Vxvalid_POD.reshape(nvalid, ntimes, kvelocity//2))\n",
    "Vxtest_POD = torch.from_numpy(Vxtest_POD.reshape(ntest, ntimes, kvelocity//2))\n",
    "Vxtrain_reconstructed = torch.from_numpy(Vxtrain_reconstructed.reshape(ntrain, ntimes, nvelocity//2))\n",
    "Vxvalid_reconstructed = torch.from_numpy(Vxvalid_reconstructed.reshape(nvalid, ntimes, nvelocity//2))\n",
    "Vxtest_reconstructed = torch.from_numpy(Vxtest_reconstructed.reshape(ntest, ntimes, nvelocity//2))\n",
    "\n",
    "Vytrain = torch.from_numpy(Vytrain.reshape(ntrain, ntimes, nvelocity//2))\n",
    "Vyvalid = torch.from_numpy(Vyvalid.reshape(nvalid, ntimes, nvelocity//2))\n",
    "Vytest = torch.from_numpy(Vytest.reshape(ntest, ntimes, nvelocity//2))\n",
    "Vytrain_POD = torch.from_numpy(Vytrain_POD.reshape(ntrain, ntimes, kvelocity//2))\n",
    "Vyvalid_POD = torch.from_numpy(Vyvalid_POD.reshape(nvalid, ntimes, kvelocity//2))\n",
    "Vytest_POD = torch.from_numpy(Vytest_POD.reshape(ntest, ntimes, kvelocity//2))\n",
    "Vytrain_reconstructed = torch.from_numpy(Vytrain_reconstructed.reshape(ntrain, ntimes, nvelocity//2))\n",
    "Vyvalid_reconstructed = torch.from_numpy(Vyvalid_reconstructed.reshape(nvalid, ntimes, nvelocity//2))\n",
    "Vytest_reconstructed = torch.from_numpy(Vytest_reconstructed.reshape(ntest, ntimes, nvelocity//2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# POD RECONSTRUCTION ERRORS ON TEST DATA\n",
    "\n",
    "Vtest_reconstructed = torch.zeros(ntest, ntimes, nvelocity)\n",
    "Vtest_reconstructed[:, :, 0 : nvelocity : 2] = Vxtest_reconstructed\n",
    "Vtest_reconstructed[:, :, 1 : nvelocity : 2] = Vytest_reconstructed\n",
    "\n",
    "print(\"Mean relative POD reconstruction error on V: %s\" % num2p(mre(Vtest, Vtest_reconstructed)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FOM vs POD RECONSTRUCTION (PLOTS)\n",
    "\n",
    "from utils.processdata import trajectories\n",
    "\n",
    "whichtrajectory = 0\n",
    "whichtimes = np.arange(0, 20)\n",
    "\n",
    "plotlist = [Vtest[whichtrajectory, whichtimes], Vtest_reconstructed[whichtrajectory, whichtimes], Vtest[whichtrajectory, whichtimes] - Vtest_reconstructed[whichtrajectory, whichtimes]]\n",
    "params_geo = MUtest[whichtrajectory, 0, 2:]\n",
    "vmin = min(np.abs(plotlist[i]).min() for i in range(len(plotlist)))\n",
    "vmax = max(np.abs(plotlist[i]).max() for i in range(len(plotlist)))\n",
    "\n",
    "trajectories(plotlist, plot_velocity, titles = (\"Velocity trajectory\", \"POD reconstruction\", \"Reconstruction error\"), figsize = (10, 5), vertical = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SHRED-ROM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# EXTRACT SENSOR DATA (SKIP THIS CELL IF DATA ALREADY AVAILABLE)\n",
    "\n",
    "nsensors = 3\n",
    "idx_sensors = np.random.choice(nvelocity//2, size = nsensors, replace = False)\n",
    "\n",
    "sensors_data_train = Vxtrain[:,:,idx_sensors]\n",
    "sensors_data_valid = Vxvalid[:,:,idx_sensors]\n",
    "sensors_data_test = Vxtest[:,:,idx_sensors]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LOAD SENSOR DATA\n",
    "\n",
    "nsensors = 3\n",
    "idx_sensors = torch.load('FlowAroundObstacle_idx_sensors_velocity.pt', weights_only = False)\n",
    "\n",
    "sensors_data_train = Vxtrain[:,:,idx_sensors]\n",
    "sensors_data_valid = Vxvalid[:,:,idx_sensors]\n",
    "sensors_data_test = Vxtest[:,:,idx_sensors]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TRAJECTORY WITH SENSORS (PLOT) \n",
    "\n",
    "def trajectory_with_sensors(vt, params_geo, idx_sensors, title = None):\n",
    "    \"\"\"\n",
    "    Velocity trajectory with sensors\n",
    "    Input: velocity trajectory with dimension (ntimes, nvelocity), geometric parameters and and the selected sensor indices\n",
    "    \"\"\"\n",
    "    \n",
    "    mesh = mesh_generator(params_geo[0], params_geo[1])\n",
    "    Vh = VectorFunctionSpace(mesh, \"CG\", 2)\n",
    "    sensors_coordinates = torch.from_numpy(Vh.sub(0).collapse().tabulate_dof_coordinates()[idx_sensors]).reshape(-1)\n",
    "    v = Function(Vh)\n",
    "    \n",
    "    vmin = vt.abs().min()\n",
    "    vmax = vt.abs().max()\n",
    "\n",
    "    for i in range(vt.shape[0]):\n",
    "        plt.figure(figsize=(10,10))\n",
    "        v.vector()[:] = vt[i]\n",
    "        plot(sqrt(inner(v, v)), cmap = cmap, vmin = vmin, vmax = vmax)\n",
    "        for k in np.arange(0, nsensors * 2, 2):\n",
    "            plt.plot(sensors_coordinates[k], sensors_coordinates[k+1], 'o', mfc = 'magenta', mec = 'black', ms = 8, mew = 1.5)\n",
    "        plt.xlim((-0.1,10.1))\n",
    "        plt.title(title)\n",
    "        plt.axis('off')\n",
    "        display(plt.gcf())\n",
    "        plt.close()\n",
    "        clc(wait=True)\n",
    "\n",
    "whichtrajectory = 0\n",
    "whichtimes = np.arange(0, 20)\n",
    "\n",
    "trajectory_with_sensors(Vtrain[whichtrajectory, whichtimes], MUtrain[whichtrajectory, 0, 2:], idx_sensors, title = \"Velocity trajectory with sensors\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# BUILD TRAIN, VALIDATION AND TEST DATASETS WITH PADDING\n",
    "\n",
    "from utils.processdata import Padding, TimeSeriesDataset\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "lag = 50\n",
    "\n",
    "train_data_in = Padding(sensors_data_train, lag).to(device)\n",
    "valid_data_in = Padding(sensors_data_valid, lag).to(device)\n",
    "test_data_in = Padding(sensors_data_test, lag).to(device)\n",
    "\n",
    "train_data_out = Padding(torch.cat((Vxtrain_POD, Vytrain_POD, MUtrain[:,:,0].unsqueeze(2)), 2), 1).squeeze(1).to(device)\n",
    "valid_data_out = Padding(torch.cat((Vxvalid_POD, Vyvalid_POD, MUvalid[:,:,0].unsqueeze(2)), 2), 1).squeeze(1).to(device)\n",
    "test_data_out = Padding(torch.cat((Vxtest_POD, Vytest_POD, MUtest[:,:,0].unsqueeze(2)), 2), 1).squeeze(1).to(device)\n",
    "\n",
    "train_dataset = TimeSeriesDataset(train_data_in, train_data_out)\n",
    "valid_dataset = TimeSeriesDataset(valid_data_in, valid_data_out)\n",
    "test_dataset = TimeSeriesDataset(test_data_in, test_data_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SHRED TRAINING (SKIP THIS CELL IF SHRED ALREADY AVAILABLE)\n",
    "\n",
    "from utils.models import SHRED, fit\n",
    "\n",
    "shred = SHRED(nsensors, kvelocity + 1, hidden_size = 64, hidden_layers = 2, decoder_sizes = [350, 400], dropout = 0.1).to(device)\n",
    "train_errors, valid_errors = fit(shred, train_dataset, valid_dataset, batch_size = 64, epochs = 100, lr = 1e-3, verbose = True, patience = 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SHRED LOADING\n",
    "\n",
    "from utils.models import SHRED\n",
    "\n",
    "shred = SHRED(nsensors, kvelocity + 1, hidden_size = 64, hidden_layers = 2, decoder_sizes = [350, 400], dropout = 0.1).to(device)\n",
    "shred.load_state_dict(torch.load('FlowAroundObstacle_shred_velocity_paramestimation.pt', weights_only = True, map_location = torch.device(device)));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SHRED ERRORS ON TEST DATA\n",
    "\n",
    "shred.freeze()\n",
    "\n",
    "test_dataset_out_hat = shred(test_data_in).cpu()\n",
    "\n",
    "alpha_in_test_hat = test_dataset_out_hat[:,-1].reshape(ntest, ntimes)\n",
    "\n",
    "Vtest_POD_hat = test_dataset_out_hat[:,:-1]\n",
    "Vxtest_hat = torch.from_numpy(scalerVx.inverse_transform(Vtest_POD_hat[:,:kvelocity//2])) @ Wx\n",
    "Vytest_hat = torch.from_numpy(scalerVy.inverse_transform(Vtest_POD_hat[:,kvelocity//2:])) @ Wy\n",
    "\n",
    "Vtest_hat = torch.zeros(ntest, ntimes, nvelocity)\n",
    "Vtest_hat[:, :, 0 : nvelocity : 2] = Vxtest_hat.reshape(ntest, ntimes, nvelocity//2)\n",
    "Vtest_hat[:, :, 1 : nvelocity : 2] = Vytest_hat.reshape(ntest, ntimes, nvelocity//2)\n",
    "\n",
    "print(\"Mean relative SHRED prediction error on V: %s\" % num2p(mre(Vtest, Vtest_hat)))\n",
    "print(\"Mean absolute SHRED prediction error on the angle of attack: %s\" % round(mae(MUtest[:,:,0], alpha_in_test_hat).item(), 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FOM vs SHRED PREDICTION (PLOTS)\n",
    "\n",
    "def trajectories_with_sensors(vts, params_geo, idx_sensors, titles = None):\n",
    "    \"\"\"\n",
    "    Trajectories with sensors\n",
    "    Input: list of trajectories with dimension (ntimes, nstate), geometric parameters and and the selected sensor indices\n",
    "    \"\"\"\n",
    "    \n",
    "    mesh = mesh_generator(params_geo[0], params_geo[1])\n",
    "    Vh = VectorFunctionSpace(mesh, \"CG\", 2)\n",
    "    sensors_coordinates = torch.from_numpy(Vh.sub(0).collapse().tabulate_dof_coordinates()[idx_sensors]).reshape(-1)\n",
    "    v = Function(Vh)\n",
    "\n",
    "    for i in range(vts[0].shape[0]):\n",
    "        \n",
    "        vmin = min(vts[j].abs().min() for j in range(len(vts)))\n",
    "        vmax = max(vts[j].abs().max() for j in range(len(vts)))\n",
    "        \n",
    "        plt.figure(figsize = (10, 5))\n",
    "        for j in range(len(vts)):\n",
    "            plt.subplot(len(vts), 1, j+1)\n",
    "            v.vector()[:] = vts[j][i]\n",
    "            plot(sqrt(inner(v, v)), cmap = cmap, vmin = vmin, vmax = vmax)\n",
    "            if j < len(vts)-1:\n",
    "               for k in np.arange(0, nsensors * 2, 2):\n",
    "                   plt.plot(sensors_coordinates[k], sensors_coordinates[k+1], 'o', mfc = 'magenta', mec = 'black', ms = 8, mew = 1.5)\n",
    "            plt.xlim((-0.1,10.1))\n",
    "            plt.title(titles[j])\n",
    "            plt.axis('off')\n",
    "        \n",
    "        display(plt.gcf())\n",
    "        plt.close()\n",
    "        clc(wait=True)\n",
    "    \n",
    "whichtrajectory = 0\n",
    "whichtimes = np.arange(180, 200)\n",
    "\n",
    "plotlist = [Vtest[whichtrajectory, whichtimes], Vtest_hat[whichtrajectory, whichtimes], Vtest[whichtrajectory, whichtimes] - Vtest_hat[whichtrajectory, whichtimes]]\n",
    "\n",
    "trajectories_with_sensors(plotlist, MUtest[whichtrajectory, 0, 2:], idx_sensors, titles = (\"Velocity trajectory\", \"SHRED prediction\", \"Prediction error\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PARAMETER vs SHRED PREDICTION (PLOT)\n",
    "\n",
    "times = np.arange(0, T, float(dt))\n",
    "\n",
    "def trajectory_parameter_estimation(MU, MU_hat, title = None):\n",
    "    \"\"\"\n",
    "    Trajectory for parameter estimation in time\n",
    "    Input: ground truth trajectory and corresponding estimate\n",
    "    \"\"\"\n",
    "    \n",
    "    plt.figure(figsize = (7,5))\n",
    "    for i in range(1, MU.shape[0] + 1):\n",
    "        plt.plot(times[:i], MU[:i], color = \"black\", linewidth = 2, label = r\"$\\alpha_{in}$\")\n",
    "        plt.plot(times[:i], MU_hat[:i], color = \"magenta\", linewidth = 2, label = r\"$\\hat {\\alpha}_{in}$\")\n",
    "        plt.plot(times[i-1], MU[i-1], 'o', color = \"black\")\n",
    "        plt.plot(times[i-1], MU_hat[i-1], 'o', color = \"magenta\")\n",
    "        if i < MU.shape[0]:\n",
    "            plt.vlines(times[i-1], -2,  2, color = \"lightgray\")\n",
    "        plt.grid()\n",
    "        plt.xlabel(\"Time $t$\", fontsize = 15)\n",
    "        plt.xticks(fontsize = 13)\n",
    "        plt.yticks(fontsize = 13)   \n",
    "        plt.xlim((times[0]-0.5, times[-1]+0.55))\n",
    "        plt.ylim((-1.2, 1.2))\n",
    "        plt.legend(fontsize = 15, loc='upper left', handlelength = 1.0, shadow = True)\n",
    "        plt.title(title, fontsize = 13)\n",
    "        display(plt.gcf())\n",
    "        plt.close()\n",
    "        clc(wait=True)\n",
    "   \n",
    "whichtrajectory = 0\n",
    "\n",
    "trajectory_parameter_estimation(MUtest[whichtrajectory,:,0], alpha_in_test_hat[whichtrajectory], title = (\"Parameter estimation\"))"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "fenicsproject",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
